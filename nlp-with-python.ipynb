{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0223b575",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-25T20:00:58.926922Z",
     "iopub.status.busy": "2023-11-25T20:00:58.926251Z",
     "iopub.status.idle": "2023-11-25T20:00:59.796058Z",
     "shell.execute_reply": "2023-11-25T20:00:59.795069Z"
    },
    "papermill": {
     "duration": 0.878606,
     "end_time": "2023-11-25T20:00:59.799840",
     "exception": false,
     "start_time": "2023-11-25T20:00:58.921234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cisi-a-dataset-for-information-retrieval/CISI.REL\n",
      "/kaggle/input/cisi-a-dataset-for-information-retrieval/CISI.ALL\n",
      "/kaggle/input/cisi-a-dataset-for-information-retrieval/CISI.QRY\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6a633",
   "metadata": {
    "papermill": {
     "duration": 0.002496,
     "end_time": "2023-11-25T20:00:59.808098",
     "exception": false,
     "start_time": "2023-11-25T20:00:59.805602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Code to populate the documents dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960d34b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:00:59.814974Z",
     "iopub.status.busy": "2023-11-25T20:00:59.814449Z",
     "iopub.status.idle": "2023-11-25T20:00:59.900764Z",
     "shell.execute_reply": "2023-11-25T20:00:59.899617Z"
    },
    "papermill": {
     "duration": 0.092447,
     "end_time": "2023-11-25T20:00:59.903118",
     "exception": false,
     "start_time": "2023-11-25T20:00:59.810671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      " 18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad. \n"
     ]
    }
   ],
   "source": [
    "def read_documents ():\n",
    "    f = open (\"/kaggle/input/cisi-a-dataset-for-information-retrieval/CISI.ALL\")\n",
    "    merged = \" \"\n",
    "    # the string variable merged keeps the result of merging the field identifier with its content\n",
    "    \n",
    "    for a_line in f.readlines ():\n",
    "        if a_line.startswith (\".\"):\n",
    "            merged += \"\\n\" + a_line.strip ()\n",
    "        else:\n",
    "            merged += \" \" + a_line.strip ()\n",
    "    # updates the merged variable using a for-loop\n",
    "    \n",
    "    documents = {}\n",
    "    \n",
    "    content = \"\"\n",
    "    doc_id = \"\"\n",
    "    # each entry in the dictioanry contains key = doc_id and value = content\n",
    "    \n",
    "    for a_line in merged.split (\"\\n\"):\n",
    "        if a_line.startswith (\".I\"):\n",
    "            doc_id = a_line.split (\" \") [1].strip()\n",
    "        elif a_line.startswith (\".X\"):\n",
    "            documents[doc_id] = content\n",
    "            content = \"\"\n",
    "            doc_id = \"\"\n",
    "        else:\n",
    "            content += a_line.strip ()[3:] + \" \"\n",
    "    f.close ()\n",
    "    return documents\n",
    "\n",
    "# print out the size of the dictionary and the content of the very first article\n",
    "documents = read_documents ()\n",
    "print (len (documents))\n",
    "print (documents.get (\"1\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea3831",
   "metadata": {
    "papermill": {
     "duration": 0.002384,
     "end_time": "2023-11-25T20:00:59.908457",
     "exception": false,
     "start_time": "2023-11-25T20:00:59.906073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Code to populate the queries dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a213c708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:00:59.915788Z",
     "iopub.status.busy": "2023-11-25T20:00:59.915253Z",
     "iopub.status.idle": "2023-11-25T20:00:59.929601Z",
     "shell.execute_reply": "2023-11-25T20:00:59.928899Z"
    },
    "papermill": {
     "duration": 0.020347,
     "end_time": "2023-11-25T20:00:59.931430",
     "exception": false,
     "start_time": "2023-11-25T20:00:59.911083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles? \n"
     ]
    }
   ],
   "source": [
    "def read_queries ():\n",
    "    f = open (\"/kaggle/input/cisi-a-dataset-for-information-retrieval/CISI.QRY\")\n",
    "    merged = \"\"\n",
    "    \n",
    "    # merge the conten of each field with its identifier and separate different fields with lune breaks\n",
    "    for a_line in f.readlines ():\n",
    "        if a_line.startswith (\".\"):\n",
    "            merged += \"\\n\" + a_line.strip ()\n",
    "        else:\n",
    "            merged += \" \" + a_line.strip ()\n",
    "    \n",
    "    queries = {}\n",
    "    \n",
    "    # initialize queries dictionary with key = qry_id and value=content for each query in the dataset\n",
    "    content = \"\"\n",
    "    qry_id = \"\"\n",
    "    \n",
    "    for a_line in merged.split (\"\\n\"):\n",
    "        if a_line.startswith (\".I\"):\n",
    "            if not content == \"\":\n",
    "                queries [qry_id] = content\n",
    "                content = \"\"\n",
    "                qry_id = \"\"\n",
    "            # add an enrty to the dictionary when you encounter an .I identifier\n",
    "            qry_id = a_line.split(\" \")[1].strip ()\n",
    "        # otherwise, keep adding content to the content variable\n",
    "        elif a_line.startswith (\".W\") or a_line.startswith (\".T\"):\n",
    "            content += a_line.strip ()[3:] + \" \"\n",
    "    queries [qry_id] = content\n",
    "    f.close ()\n",
    "    return queries\n",
    "\n",
    "# print out the length of the dictionary and the content of the first query\n",
    "queries = read_queries ()\n",
    "print (len (queries))\n",
    "print (queries.get(\"1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21071fed",
   "metadata": {
    "papermill": {
     "duration": 0.002434,
     "end_time": "2023-11-25T20:00:59.936815",
     "exception": false,
     "start_time": "2023-11-25T20:00:59.934381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Code to populate the mappings dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e74087e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:00:59.943767Z",
     "iopub.status.busy": "2023-11-25T20:00:59.943243Z",
     "iopub.status.idle": "2023-11-25T20:00:59.958944Z",
     "shell.execute_reply": "2023-11-25T20:00:59.957865Z"
    },
    "papermill": {
     "duration": 0.021547,
     "end_time": "2023-11-25T20:00:59.960888",
     "exception": false,
     "start_time": "2023-11-25T20:00:59.939341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '37', '39', '41', '42', '43', '44', '45', '46', '49', '50', '52', '54', '55', '56', '57', '58', '61', '62', '65', '66', '67', '69', '71', '76', '79', '81', '82', '84', '90', '92', '95', '96', '97', '98', '99', '100', '101', '102', '104', '109', '111'])\n",
      "['28', '35', '38', '42', '43', '52', '65', '76', '86', '150', '189', '192', '193', '195', '215', '269', '291', '320', '429', '465', '466', '482', '483', '510', '524', '541', '576', '582', '589', '603', '650', '680', '711', '722', '726', '783', '813', '820', '868', '869', '894', '1162', '1164', '1195', '1196', '1281']\n"
     ]
    }
   ],
   "source": [
    "def read_mappings ():\n",
    "    f = open (\"/kaggle/input/cisi-a-dataset-for-information-retrieval/CISI.REL\")\n",
    "    mappings = {}\n",
    "    \n",
    "    for a_line in f.readlines ():\n",
    "        voc = a_line.strip ().split ()\n",
    "        key = voc[0].strip ()\n",
    "        current_value = voc[1].strip()\n",
    "        value = []\n",
    "        # update the entry in the mappings dictionary with the current value\n",
    "        if key in mappings.keys ():\n",
    "            value = mappings.get (key)\n",
    "        value.append (current_value)\n",
    "        mappings [key] = value\n",
    "    f.close ()\n",
    "    return mappings\n",
    "\n",
    "# print out some information about the mapping data structure\n",
    "mappings = read_mappings ()\n",
    "print (len (mappings))\n",
    "print (mappings.keys ())\n",
    "print (mappings.get (\"1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73d1d14",
   "metadata": {
    "papermill": {
     "duration": 0.003017,
     "end_time": "2023-11-25T20:00:59.967314",
     "exception": false,
     "start_time": "2023-11-25T20:00:59.964297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Preprocess the data in documents and queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "649c973a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:00:59.975122Z",
     "iopub.status.busy": "2023-11-25T20:00:59.974432Z",
     "iopub.status.idle": "2023-11-25T20:01:03.493617Z",
     "shell.execute_reply": "2023-11-25T20:01:03.492389Z"
    },
    "papermill": {
     "duration": 3.525868,
     "end_time": "2023-11-25T20:01:03.496128",
     "exception": false,
     "start_time": "2023-11-25T20:00:59.970260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "['18', 'editions', 'of', 'the', 'dewey', 'decimal', 'classifications', 'comaromi', ',', 'j.p.', 'the', 'present', 'study', 'is', 'a', 'history', 'of', 'the', 'dewey', 'decimal', 'classification', '.', 'the', 'first', 'edition', 'of', 'the', 'ddc', 'was', 'published', 'in', '1876', ',', 'the', 'eighteenth', 'edition', 'in', '1971', ',', 'and', 'future', 'editions', 'will', 'continue', 'to', 'appear', 'as', 'needed', '.', 'in', 'spite', 'of', 'the', 'ddc', \"'s\", 'long', 'and', 'healthy', 'life', ',', 'however', ',', 'its', 'full', 'story', 'has', 'never', 'been', 'told', '.', 'there', 'have', 'been', 'biographies', 'of', 'dewey', 'that', 'briefly', 'describe', 'his', 'system', ',', 'but', 'this', 'is', 'the', 'first', 'attempt', 'to', 'provide', 'a', 'detailed', 'history', 'of', 'the', 'work', 'that', 'more', 'than', 'any', 'other', 'has', 'spurred', 'the', 'growth', 'of', 'librarianship', 'in', 'this', 'country', 'and', 'abroad', '.']\n",
      "113\n",
      "112\n",
      "['what', 'problems', 'and', 'concerns', 'are', 'there', 'in', 'making', 'up', 'descriptive', 'titles', '?', 'what', 'difficulties', 'are', 'involved', 'in', 'automatically', 'retrieving', 'articles', 'from', 'approximate', 'titles', '?', 'what', 'is', 'the', 'usual', 'relevance', 'of', 'the', 'content', 'of', 'articles', 'to', 'their', 'titles', '?']\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# text is converted to lowercase and split into words\n",
    "def get_words (text):\n",
    "    word_list = [word for word in word_tokenize (text.lower ())]\n",
    "    return word_list\n",
    "    \n",
    "doc_words = {}\n",
    "qry_words = {}\n",
    "\n",
    "for doc_id in documents.keys ():\n",
    "    doc_words [doc_id] = get_words (documents.get (doc_id))\n",
    "for qry_id in queries.keys ():\n",
    "    # entries in both documents and queries are represented as word lists\n",
    "    qry_words [qry_id] = get_words (queries.get (qry_id))\n",
    "    \n",
    "# print out the length of the dictionaries and check the first document and the fisrt query\n",
    "print (len (doc_words))\n",
    "print (doc_words.get (\"1\"))\n",
    "print (len (doc_words.get (\"1\")))\n",
    "print (len (qry_words))\n",
    "print (qry_words.get (\"1\"))\n",
    "print (len (qry_words.get(\"1\")))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 576263,
     "sourceId": 1043323,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.353821,
   "end_time": "2023-11-25T20:01:04.122115",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-25T20:00:54.768294",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
